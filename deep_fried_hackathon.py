# -*- coding: utf-8 -*-
"""Deep Fried Hackathon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ezejed-weyZtO6N6HMv2QvVDqw_FpDAS
"""

# 1. Installations et imports
!pip install boto3 tqdm pillow

import boto3
import pandas as pd
import os
import re
import io
import json
import base64
import time
from tqdm import tqdm
from PIL import Image



# 2. Cl√©s AWS et connexion √† S3 + Bedrock
aws_access_key_id = "AKIAQFCCVB2BUPOA4IMU"
aws_secret_access_key = "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"
region_name = "us-west-2"
bucket_name = "rakutenproducts"  # Remplace par le vrai nom du bucket

# Connexion S3
s3 = boto3.client(
    's3',
    aws_access_key_id=aws_access_key_id,
    aws_secret_access_key=aws_secret_access_key,
    region_name=region_name
)

# Connexion Bedrock
bedrock_runtime = boto3.client(
    'bedrock-runtime',
    aws_access_key_id=aws_access_key_id,
    aws_secret_access_key=aws_secret_access_key,
    region_name=region_name
)

MODEL_ID = 'anthropic.claude-3-sonnet-20240229'
#Excellente compr√©hension s√©mantique

# 3. T√©l√©charger le CSV depuis S3
csv_key = 'X_train_update.csv'  # Le nom exact du fichier CSV dans le bucket
csv_obj = s3.get_object(Bucket=bucket_name, Key=csv_key)
df = pd.read_csv(io.BytesIO(csv_obj['Body'].read()))

print("CSV charg√©. Extrait des 3 premi√®res lignes :")
print(df.head(3))

try:
    csv_key = 'X_train_update.csv'  # Nom exact du fichier dans le bucket
    csv_obj = s3.get_object(Bucket=bucket_name, Key=csv_key)
    df = pd.read_csv(io.BytesIO(csv_obj['Body'].read()))

    print("‚úÖ CSV charg√© avec succ√®s. Aper√ßu :")
    display(df.head(3))

except Exception as e:
    print("‚ùå Erreur lors du chargement du CSV :", e)

# 5. Lister les 500 images du dossier rakutenpremieresimagesdudossier/ (tri d√©croissant)
def list_sorted_image_keys(bucket, prefix, limit=500):
    all_keys = []
    continuation_token = None

    while True:
        kwargs = {'Bucket': bucket, 'Prefix': prefix}
        if continuation_token:
            kwargs['ContinuationToken'] = continuation_token
        response = s3.list_objects_v2(**kwargs)
        contents = response.get('Contents', [])
        all_keys.extend([obj['Key'] for obj in contents if obj['Key'].endswith('.jpg')])
        if response.get("IsTruncated"):
            continuation_token = response["NextContinuationToken"]
        else:
            break

    return sorted(all_keys, reverse=True)[:limit]

bucket_name = "rakutenpremieresimagesdudossier"  # ‚úÖ c'est le nom du BUCKET

image_keys = list_sorted_image_keys(bucket_name, prefix="", limit=500)

# üß© Construire image_map avec seulement les 500 images
pattern = re.compile(r'image_(\d+)_product')
image_map = {}

for key in image_keys:
    match = pattern.search(key)
    if match:
        image_id = match.group(1)
        image_map[image_id] = key

print(f"‚úÖ {len(image_map)} images dans le mapping")
print("üîç Exemple image_map :")
print(list(image_map.items())[:3])

# 6. Prendre les 500 derni√®res lignes du CSV (ordre d√©croissant)
df_sorted = df.sort_values(by='imageid', ascending=False)
df_500 = df_sorted[df_sorted['imageid'].astype(str).isin(image_map.keys())].head(500).copy()

print(f"‚úÖ {len(df_500)} lignes s√©lectionn√©es avec image dispo")

# 4. Liste des cat√©gories Rakuten
categories = [
    "Livre", "Musique CD", "DVD Blu-Ray", "Jeux vid√©o Console", "T√©l√©phonie Tablette",
    "Informatique Logiciel", "TV Image et Son", "Maison", "Electrom√©nager", "Alimentation Boisson",
    "Brico Jardin Animalerie", "Sport Loisirs", "Mode", "Beaut√©", "Jouet Enfant Pu√©riculture",
    "Auto-Moto", "Le coin des collectionneurs", "Rakuten services"
]
categories_str = ', '.join(categories)



import re

# 5. Indexer toutes les images valides (pr√©sentes dans le CSV)
pattern = re.compile(r'image_(\d+)_product')  # extrait image_id √† partir du nom du fichier
csv_imageids = set(df['imageid'].astype(str))  # liste des image_id pr√©sents dans le CSV

def list_all_keys_paginated(prefix):
    all_keys = []
    continuation_token = None
    while True:
        kwargs = {'Bucket': bucket_name, 'Prefix': prefix}
        if continuation_token:
            kwargs['ContinuationToken'] = continuation_token
        response = s3.list_objects_v2(**kwargs)
        contents = response.get('Contents', [])
        all_keys.extend([obj['Key'] for obj in contents if obj['Key'].endswith('.jpg')])
        if response.get('IsTruncated'):
            continuation_token = response['NextContinuationToken']
        else:
            break
    return all_keys

# Dictionnaire image_id ‚Üí chemin S3 de l‚Äôimage
image_map = {}

# Explorer les deux dossiers d‚Äôimages
for prefix in ['image_test/', 'image_train/']:
    keys = list_all_keys_paginated(prefix)
    for key in keys:
        match = pattern.search(key)
        if match:
            image_id = match.group(1)
            if image_id in csv_imageids:
                image_map[image_id] = key

print(f"Nombre d‚Äôimages filtr√©es li√©es au CSV : {len(image_map)}")
print("Exemples de correspondances image_id ‚Üí image_key :")
for i, (img_id, s3_key) in enumerate(image_map.items()):
    print(f"{img_id} ‚Üí {s3_key}")
    if i == 4: break  # Afficher 5 exemples max

# 6. Fonction pour encoder une image S3 en base64
def get_image_base64_from_s3(image_key):
    try:
        obj = s3.get_object(Bucket=bucket_name, Key=image_key)
        image_bytes = obj['Body'].read()
        return base64.b64encode(image_bytes).decode('utf-8')
    except Exception as e:
        print(f"Erreur t√©l√©chargement image {image_key} : {e}")
        return None

def call_bedrock_with_image_and_text(description, designation, image_b64):
    champ_utilise = description if pd.notnull(description) and str(description).strip() else designation

    prompt = (
        "Tu es un agent IA de cat√©gorisation pour Rakuten. "
        "Voici un produit √† classer dans l'une des cat√©gories suivantes :\n"
        f"{categories_str}\n\n"
        f"Donn√©es produit :\n"
        f"- Nom ou d√©signation : {champ_utilise}\n"
        f"- Image encod√©e en base64 (indice visuel) : {image_b64[:300]}...\n\n"
        "R√©ponds uniquement par le nom de la cat√©gorie la plus probable, sans explication."
    )

    body = json.dumps({
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 100,
        "temperature": 0.0,
        "top_p": 1.0,
        "stop_sequences": []
    })

    try:
        response = bedrock_runtime.invoke_model(
            modelId=MODEL_ID,
            contentType="application/json",
            accept="application/json",
            body=body
        )
        result = json.loads(response['body'].read())

        # Debug si vide
        if "content" not in result or not result["content"]:
            print(f"R√©ponse vide ou inattendue : {result}")
            return "Erreur"

        return result["content"].strip()

    except Exception as e:
        print(f"Erreur appel Claude : {e}")
        return "Erreur"

# 8. Appliquer la classification ligne par ligne
results = []
for idx, row in tqdm(df_500.iterrows(), total=len(df_500)):
    try:
        image_id = str(row.get('imageid')).split('.')[0]
        image_key = image_map.get(image_id)
        image_b64 = get_image_base64_from_s3(image_key) if image_key else None
        cat = call_bedrock_with_image_and_text(row.get('description', ''), row.get('designation', ''), image_b64)
    except Exception as e:
        print(f"Erreur sur ligne {idx} : {e}")
        cat = "Erreur"
    results.append(cat)
    time.sleep(0.2)  # limite de requ√™tes Bedrock

df_500['categorie_rakuten'] = results

# 9. Export CSV enrichi
df_500.to_csv("X_train_update_500_categorise.csv", index=False)

from google.colab import files
files.download("X_train_update_500_categorise.csv")

image_id = str(image_id).split('.')[0]
image_key = image_map.get(1000139370)

print("Image ID :", image_id)
print("Image Key trouv√© dans image_map :", image_key)

try:
    obj = s3.get_object(Bucket=bucket_name, Key=image_key)
    print("‚úîÔ∏è Image trouv√©e dans S3. Taille :", obj['ContentLength'], "bytes")
except Exception as e:
    print("Erreur acc√®s S3 :", e)

# Exemple sur quelques lignes
for i in range(5):
    print(f"Row {i}:")
    print("  imageid CSV =", df.iloc[i]['imageid'], "| type =", type(df.iloc[i]['imageid']))
    print("  str(imageid) =", str(df.iloc[i]['imageid']), "| existe dans image_map ? =>", str(df.iloc[i]['imageid']) in image_map)

# Affiche les premiers IDs dans le CSV
csv_imageids = df['imageid'].astype(str).tolist()
print("Exemples imageid du CSV :", csv_imageids[:5])

# Affiche les premiers IDs dans image_map
print("Exemples imageid dans image_map :", list(image_map.keys())[:5])

# Cherche s'il y a des IDs du CSV qui apparaissent en partie dans les cl√©s S3 (diagnostic manuel)
print("üîç CSV imageids pr√©sents dans image_map ?")
for i in range(5):
    imageid = csv_imageids[i]
    s3_keys = [v for k, v in image_map.items() if imageid in v]
    print(f"imageid {imageid} ‚Üí trouv√© dans S3 ? {'‚úÖ' if s3_keys else '‚ùå'}")
    if s3_keys:
        print(f"  ‚Üí Exemple cl√© : {s3_keys[0]}")

!pip install boto3

import boto3
import os

bucket = "NOM_BUCKET"   # ex: "rakuten-images-prod"
prefix = "images/"      # ex: "images/" ou "" si tes images sont √† la racine

aws_access_key_id = "TA_CLE_ACCESS_KEY_ID"
aws_secret_access_key = "TON_SECRET_ACCESS_KEY"
region_name = "us-west-2"  # adapte √† ta r√©gion S3

s3 = boto3.client(
    's3',
    aws_access_key_id=aws_access_key_id,
    aws_secret_access_key=aws_secret_access_key,
    region_name=region_name
)

image_files = []
continuation_token = None

while True:
    list_kwargs = dict(Bucket=bucket, Prefix=prefix)
    if continuation_token:
        list_kwargs["ContinuationToken"] = continuation_token
    response = s3.list_objects_v2(**list_kwargs)
    if 'Contents' in response:
        image_files.extend([obj['Key'].split('/')[-1] for obj in response['Contents']])
    if response.get('IsTruncated'):
        continuation_token = response['NextContinuationToken']
    else:
        break

# Garde uniquement les noms de fichiers non vides et ayant une extension
image_ids_available = {os.path.splitext(f)[0] for f in image_files if '.' in f and f}
print(f"{len(image_ids_available)} images trouv√©es sur S3")